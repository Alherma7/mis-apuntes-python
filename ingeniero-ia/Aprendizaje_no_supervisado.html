<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Sheetcheat — Aprendizaje no supervisado en Python</title>
  <style>
    body {
      font-family: "Segoe UI", sans-serif;
      background-color: #f9f9f9;
      padding: 30px;
      color: #333;
    }
    h1, h2 {
      color: #145374;
    }
    code {
      background-color: #e6f2ff;
      padding: 3px 6px;
      border-radius: 4px;
      font-family: Consolas, monospace;
    }
    pre {
      background-color: #e6f2ff;
      padding: 12px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.95em;
    }
    section {
      margin-bottom: 40px;
    }
  </style>
</head>
<body>

  <h1>🌀 Sheetcheat — Aprendizaje no supervisado en Python</h1>

  <section>
    <h2>🔍 Clustering con KMeans</h2>
    <pre><code>from sklearn.cluster import KMeans

model = KMeans(n_clusters=3)
model.fit(points)
labels = model.predict(new_points)
print(labels)</code></pre>
  </section>

  <section>
    <h2>📊 Visualización de grupos y centroides</h2>
    <pre><code>xs = new_points[:, 0]
ys = new_points[:, 1]

plt.scatter(xs, ys, c=labels, alpha=0.5)
centroids = model.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1], marker='D', s=50)
plt.show()</code></pre>
  </section>

  <section>
    <h2>📈 Determinación del número óptimo de clusters</h2>
    <pre><code>ks = range(1, 6)
inertias = []

for k in ks:
    model = KMeans(n_clusters=k)
    model.fit(samples)
    inertias.append(model.inertia_)

plt.plot(ks, inertias, '-o')
plt.xlabel('Número de clusters, k')
plt.ylabel('Inercia')
plt.xticks(ks)
plt.show()</code></pre>
  </section>

  <section>
    <h2>⚙️ Agrupación y evaluación con tabulación cruzada</h2>
    <pre><code>labels = model.fit_predict(samples)
df = pd.DataFrame({'labels': labels, 'varieties': varieties})
ct = pd.crosstab(df['labels'], df['varieties'])
print(ct)</code></pre>
  </section>

  <section>
    <h2>🔁 Pipeline para escalar y agrupar</h2>
    <pre><code>from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
kmeans = KMeans(n_clusters=4)
pipeline = make_pipeline(scaler, kmeans)

pipeline.fit(samples)
labels = pipeline.predict(samples)</code></pre>
  </section>

  <section>
    <h2>📉 Reducción dimensional con PCA y t-SNE</h2>
    <pre><code>from sklearn.decomposition import PCA
model = PCA(n_components=2)
pca_features = model.fit_transform(scaled_samples)
print(pca_features.shape)</code></pre>

    <pre><code>from sklearn.manifold import TSNE
model = TSNE(learning_rate=200)
tsne_features = model.fit_transform(samples)

xs = tsne_features[:, 0]
ys = tsne_features[:, 1]
plt.scatter(xs, ys, c=variety_numbers)
plt.show()</code></pre>
  </section>

  <section>
    <h2>📚 Análisis de texto con NMF y tf-idf</h2>
    <pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()
csr_mat = tfidf.fit_transform(documents)
words = tfidf.get_feature_names_out()
print(words)</code></pre>

    <pre><code>from sklearn.decomposition import NMF
model = NMF(n_components=6)
nmf_features = model.fit_transform(articles)
df = pd.DataFrame(nmf_features, index=titles)
similarities = df.dot(df.loc["Cristiano Ronaldo"])
print(similarities.nlargest())</code></pre>
  </section>

  <section>
    <h2>🎵 Recomendación musical con NMF</h2>
    <pre><code>from sklearn.preprocessing import MaxAbsScaler, Normalizer
from sklearn.pipeline import make_pipeline

scaler = MaxAbsScaler()
nmf = NMF(n_components=20)
normalizer = Normalizer()
pipeline = make_pipeline(scaler, nmf, normalizer)

norm_features = pipeline.fit_transform(artists)
df = pd.DataFrame(norm_features, index=artist_names)

similarities = df.dot(df.loc["Bruce Springsteen"])
print(similarities.nlargest())</code></pre>
  </section>

</body>
</html>
