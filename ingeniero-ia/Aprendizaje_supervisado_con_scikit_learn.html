<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Sheetcheat ‚Äî Aprendizaje supervisado con Scikit-learn</title>
  <style>
    body {
      font-family: "Segoe UI", sans-serif;
      background-color: #f9f9f9;
      padding: 30px;
      color: #333;
    }
    h1, h2 {
      color: #145374;
    }
    code {
      background-color: #e6f2ff;
      padding: 3px 6px;
      border-radius: 4px;
      font-family: Consolas, monospace;
    }
    pre {
      background-color: #e6f2ff;
      padding: 12px;
      border-radius: 6px;
      overflow-x: auto;
      font-size: 0.95em;
    }
    section {
      margin-bottom: 40px;
    }
  </style>
</head>
<body>

  <h1>üìò Sheetcheat ‚Äî Aprendizaje supervisado con Scikit-learn</h1>

  <section>
    <h2>üìö Conceptos clave</h2>
    <ul>
      <li>Diferencia entre aprendizaje supervisado vs no supervisado</li>
      <li>Features y variable objetivo (target)</li>
      <li>Clasificaci√≥n vs regresi√≥n</li>
      <li>Modelos b√°sicos: <code>KNeighborsClassifier</code>, <code>LinearRegression</code>, <code>Ridge</code>, <code>Lasso</code></li>
      <li>M√©tricas: <code>accuracy</code>, <code>confusion matrix</code>, <code>precision</code>, <code>recall</code>, <code>F1-score</code>, <code>ROC AUC</code></li>
    </ul>
  </section>

  <section>
    <h2>üßº Preprocesamiento y Validaci√≥n</h2>
    <pre><code>from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</code></pre>

    <pre><code>from sklearn.pipeline import Pipeline

steps = [("imputer", SimpleImputer()),
         ("scaler", StandardScaler()),
         ("model", LogisticRegression())]

pipeline = Pipeline(steps)
pipeline.fit(X_train, y_train)</code></pre>
  </section>

  <section>
    <h2>üîç Evaluaci√≥n del modelo</h2>
    <pre><code>from sklearn.metrics import roc_auc_score, confusion_matrix

y_probs = logreg.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_probs)

print("ROC AUC:", roc_auc)
print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, logreg.predict(X_test)))</code></pre>
  </section>

  <section>
    <h2>üí° Validaci√≥n cruzada y comparaci√≥n de modelos</h2>
    <pre><code>from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso

kf = KFold(n_splits=6, shuffle=True)
models = [LinearRegression(), Ridge(), Lasso()]

for m in models:
    scores = cross_val_score(m, X, y, cv=kf)
    print(type(m).__name__, scores)</code></pre>
  </section>

  <section>
    <h2>‚öôÔ∏è B√∫squeda de hiperpar√°metros</h2>
    <pre><code>from sklearn.model_selection import GridSearchCV

param_grid = {"n_neighbors": [3, 5, 7]}
grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)

print("Mejor combinaci√≥n:", grid.best_params_)</code></pre>
  </section>

  <section>
    <h2>üéµ Ejercicio aplicado: predicci√≥n musical</h2>
    <pre><code>from sklearn.model_selection import cross_val_score

X = music_df.drop("genre", axis=1)
y = music_df["genre"]

model = RandomForestClassifier()
scores = cross_val_score(model, X, y, cv=5)

print("Exactitud promedio:", scores.mean())</code></pre>
  </section>

</body>
</html>
